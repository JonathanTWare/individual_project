{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a887fef0",
   "metadata": {},
   "source": [
    "# Zillow Project - Predicting Property Tax Assessed Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acc8d2f",
   "metadata": {},
   "source": [
    "# Goal:\n",
    "\n",
    "  Use the data from kaggle's chicago crime data set in order to predict specific crime counts for next year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce6a014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model as m\n",
    "import wrangle as w\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sqlalchemy import text, create_engine\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import Holt, ExponentialSmoothing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt \n",
    "from sklearn.linear_model import LinearRegression\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543e3cfb",
   "metadata": {},
   "source": [
    "# Acquire\n",
    "    -Data acquired Kaggle's Chicago Crime dataset\n",
    "    -It contained '7842388' rows and '10' columns before cleaning\n",
    "    -Each row represents a case number\n",
    "    -Each column represents a feature of that case number\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f264ef",
   "metadata": {},
   "source": [
    "#  Prepare\n",
    "\n",
    "### Prepare Actions:\n",
    "```\n",
    "- Checked for nulls in the data \n",
    "- Checked that column data types were appropriate\n",
    "- Split data into train, validate and test \n",
    "- created function to acquire and prep data\n",
    "- function created to split data into train, validate and test\n",
    "- resample data by day\n",
    "- unstacked 'Primary Type'\n",
    "- kept 10 primary type values\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15c9745",
   "metadata": {},
   "source": [
    "## Data Dictionary  \n",
    "\n",
    "\n",
    "#### Data Used\n",
    "---\n",
    "| Attribute | Definition | Data Type |\n",
    "| ----- | ----- | ----- |\n",
    "|Date| Dates in order by day |int|\n",
    "|THEFT| Amount of thefts that has occured in a particular day |int|\n",
    "|BATTERY|Amount of battery that havs occured in a particular day |int|\n",
    "|ASSAULT| Amount of assault that has occured in a particular day |int|\n",
    "|CRIMINAL DAMAGE| Amount of criminal damage that has occured in a particular day |int|\n",
    "|MOTOR VEHICLE THEFT| Amount of motor vehicle theft that has occured in a particular day |int|\n",
    "|NARCOTICS|Amount of narcotic related crimes that have occured in a particular day |int|\n",
    "|HOMICIDE| Amount of homicides that have occured in a particular day|int|\n",
    "|HUMAN TRAFFICKING| Amount of human trafficking that has occured in a particular day |int|\n",
    "|OFFENSE INVOLVING CHILDREN| Amount of offenses involving children that have occured in a particular day|int|\n",
    "|KIDNAPPING| Amount of kidnapping that has occured in a particular day |int|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214736b3",
   "metadata": {},
   "source": [
    "## Quick Data Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da5659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train, validate and test\n",
    "train, validate, test = w.wrangle_crime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a683488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this previews the training data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93618fc1",
   "metadata": {},
   "source": [
    "## Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43c8c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provides a quick description of the data\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21af930e",
   "metadata": {},
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab47d414",
   "metadata": {},
   "source": [
    "## Which crimes show a correlation with time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88acd1be-a280-4181-bd4d-4964c6e3f25e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "crime_types = train.columns\n",
    "\n",
    "# Call the function with the train DataFrame and the crime types list\n",
    "m.plot_autocorrelation(train, crime_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e017db7e",
   "metadata": {},
   "source": [
    " - Visually no apparent correlation except a weak correlation with the following crimes: Assault, battery and criminal damages\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b508c2f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Exploration Summary\n",
    "Assault, battery and criminal damages all seem to have some kind of correlation with time\n",
    "\n",
    "- Revisisting data for more exploration may be necessary for predictability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa359a7",
   "metadata": {},
   "source": [
    "## Features being turned into targets for Modeling by creating their own DataFrame's with Lag:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32358a15",
   "metadata": {},
   "source": [
    "- ASSAULT - (relationship to time is weak but present)\n",
    "\n",
    "- BATTERY - (relationship to time is weak but present)\n",
    "\n",
    "- CRIMINAL DAMAGE -  (relationship to time is weak but present)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcd3226",
   "metadata": {},
   "source": [
    "## Features not moving forward for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eef51f",
   "metadata": {},
   "source": [
    "```\n",
    "'THEFT'\n",
    "'MOTOR VEHICLE THEFT'\n",
    "'NARCOTICS'\n",
    "'HOMICIDE'\n",
    "'HUMAN TRAFFICKING'\n",
    "'OFFENSE INVOLVING CHILDREN'\n",
    "'KIDNAPPING'\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80340c71",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912395c9",
   "metadata": {},
   "source": [
    "- I will use 3 Baseline models to find best baseline RMSE and 2 non-baseline models to find best RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2238047d",
   "metadata": {},
   "source": [
    "- Best Baseline to use for modeling was Moving Average (30 day window) \n",
    "- I will be evaluating models developed using 5 different model types.\n",
    "- Models will be evaluated on train and validate data \n",
    "- The model that performs the best will then be evaluated on test data\n",
    "- Data will be passed through as lag columns of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64560bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = m.create_lagged_features(train, crime_types, max_lag=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f434bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78979c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "battery_train = ['BATTERY'] + [f'BATTERY_Lag_{lag}' for lag in range(1, 366)]\n",
    "\n",
    "battery_train_df = train[battery_train].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e8bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criminal_damage_train = ['CRIMINAL DAMAGE'] + [f'CRIMINAL_DAMAGE_Lag_{lag}' for lag in range(1, 366)]\n",
    "\n",
    "criminal_damage_train_df = train[criminal_damage_train].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cd248e-8917-4717-a64f-1c9fe7441dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "assault_train = ['ASSAULT'] + [f'ASSAULT_Lag_{lag}' for lag in range(1, 366)]\n",
    "\n",
    "assault_train_df = train[assault_train].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ce2777-2bdd-4545-a811-b6ba44fb3979",
   "metadata": {},
   "source": [
    "### Models for Predicting Assault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b970ef-5130-42a4-b42f-897801a5ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = m.evaluate_assault_model(assault_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b59f254",
   "metadata": {},
   "source": [
    "### LinearRegression (OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0effccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# MAKE THE THING: create the model object\n",
    "OLSmodel = LinearRegression()\n",
    "\n",
    "#1. FIT THE THING: fit the model to training data\n",
    "\n",
    "OLSmodel.fit(X_train, y_train.tax_value)\n",
    "#2. USE THE THING: make a prediction\n",
    "y_train['value_pred_ols'] = OLSmodel.predict(X_train)\n",
    "\n",
    "#3. Evaluate: RMSE\n",
    "rmse_train = mean_squared_error(y_train.tax_value, y_train.value_pred_ols) **.5\n",
    "\n",
    "#4. REPEAT STEPS 2-3\n",
    "\n",
    "# predict validate\n",
    "y_validate['value_pred_ols'] = OLSmodel.predict(X_validate)\n",
    "\n",
    "# evaluate: RMSE\n",
    "rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.value_pred_ols) ** .5\n",
    "\n",
    "rmse_train = round(rmse_train, 2)\n",
    "rmse_validate = round(rmse_validate, 2)\n",
    "difference = round(rmse_validate - rmse_train, 2)\n",
    "\n",
    "\n",
    "model_rmse.append({\n",
    "    'model': 'OLS',\n",
    "'Training/In-Sample': rmse_train, \n",
    "'Validation/Out-of-Sample': rmse_validate,\n",
    "'Difference':  rmse_validate - rmse_train,\n",
    "\n",
    "})\n",
    "pd.DataFrame(model_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c70588",
   "metadata": {},
   "source": [
    "### LassoLars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977dbff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MAKE THE THING: create the model object\n",
    "lars = LassoLars(alpha = 0.01)\n",
    "\n",
    "#1. FIT THE THING: fit the model to training data\n",
    "\n",
    "lars.fit(X_train, y_train.tax_value)\n",
    "#2. USE THE THING: make a prediction\n",
    "y_train['value_pred_lars'] = lars.predict(X_train)\n",
    "\n",
    "#3. Evaluate: RMSE\n",
    "rmse_train = mean_squared_error(y_train.tax_value, y_train.value_pred_lars) **.5\n",
    "\n",
    "#4. REPEAT STEPS 2-3\n",
    "\n",
    "# predict validate\n",
    "y_validate['value_pred_lars'] = lars.predict(X_validate)\n",
    "\n",
    "# evaluate: RMSE\n",
    "rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.value_pred_lars) ** .5\n",
    "\n",
    "rmse_train = round(rmse_train, 2)\n",
    "rmse_validate = round(rmse_validate, 2)\n",
    "difference = round(rmse_validate - rmse_train, 2)\n",
    "\n",
    "\n",
    "model_rmse.append({\n",
    "    'model': 'LassoLars',\n",
    "'Training/In-Sample': rmse_train, \n",
    "'Validation/Out-of-Sample': rmse_validate,\n",
    "'Difference':  rmse_validate - rmse_train,\n",
    "\n",
    "})\n",
    "pd.DataFrame(model_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce86a4c1",
   "metadata": {},
   "source": [
    "### TweedieRegressor (GLM:Generalized Linear Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d6165",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# MAKE THE THING: create the model object\n",
    "glm = TweedieRegressor(power = 2, alpha = 0.2)\n",
    "\n",
    "glm.fit(X_train, y_train.tax_value)\n",
    "#2. USE THE THING: make a prediction\n",
    "y_train['value_pred_glm'] = glm.predict(X_train)\n",
    "\n",
    "#3. Evaluate: RMSE\n",
    "rmse_train = mean_squared_error(y_train.tax_value, y_train.value_pred_glm) **.5\n",
    "\n",
    "#4. REPEAT STEPS 2-3\n",
    "\n",
    "# predict validate\n",
    "y_validate['value_pred_glm'] = glm.predict(X_validate)\n",
    "\n",
    "# evaluate: RMSE\n",
    "rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.value_pred_glm) ** .5\n",
    "\n",
    "\n",
    "rmse_train = round(rmse_train, 2)\n",
    "rmse_validate = round(rmse_validate, 2)\n",
    "difference = round(rmse_validate - rmse_train, 2)\n",
    "\n",
    "\n",
    "model_rmse.append({\n",
    "'model': 'GLM',\n",
    "'Training/In-Sample': rmse_train, \n",
    "'Validation/Out-of-Sample': rmse_validate,\n",
    "'Difference':  rmse_validate - rmse_train,\n",
    "\n",
    "})\n",
    "pd.DataFrame(model_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97adc642",
   "metadata": {},
   "source": [
    "### Ploynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79da6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_validate_poly = poly.transform(X_validate)\n",
    "\n",
    "# Fit the polynomial regression model\n",
    "poly_reg = LinearRegression()\n",
    "poly_reg.fit(X_train_poly, y_train.tax_value)\n",
    "\n",
    "# Make predictions on training set\n",
    "y_train['value_pred_poly'] = poly_reg.predict(X_train_poly)\n",
    "rmse_train = mean_squared_error(y_train.tax_value, y_train.value_pred_poly) ** 0.5\n",
    "\n",
    "# Make predictions on validation set\n",
    "y_validate['value_pred_poly'] = poly_reg.predict(X_validate_poly)\n",
    "rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.value_pred_poly) ** 0.5\n",
    "\n",
    "rmse_train = round(rmse_train, 2)\n",
    "rmse_validate = round(rmse_validate, 2)\n",
    "difference = round(rmse_validate - rmse_train, 2)\n",
    "\n",
    "\n",
    "model_rmse.append({\n",
    "    'model': 'Poly',\n",
    "'Training/In-Sample': rmse_train, \n",
    "'Validation/Out-of-Sample': rmse_validate,\n",
    "'Difference':  rmse_validate - rmse_train,\n",
    "\n",
    "})\n",
    "pd.DataFrame(model_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828b435a",
   "metadata": {},
   "source": [
    "# Comparing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b8761a",
   "metadata": {},
   "source": [
    "- All models outperformed baseline\n",
    "- LassoLars and Linear Regression models had a slightly lower error reduction at 15% better than baseline.\n",
    "- The TweedieRegressor model barely outperformed baseline by 6%.\n",
    "- Considering all models, as they did all beat baseline, Polynomial Regression model outperformed baseline by 17% which was the highest in error reduction.\n",
    "- I will be using my polynomial regression model to run on test as it performed the best for seen and unseen data with the lowest RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d14278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code runs test on polynomial regression\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "y_test_pred = poly_reg.predict(X_test_poly)\n",
    "\n",
    "rmse_test = mean_squared_error(y_test, y_test_pred) ** 0.5\n",
    "\n",
    "print(f\"RMSE on Test Set: {rmse_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031abe99",
   "metadata": {},
   "source": [
    "### Modeling Summary\n",
    "- All models performed better than baseline\n",
    "- RMSE on POLY Test Set beats baselines RMSE train and RMSE validate by approximately 76,000  dollars less in error which equates to 18% error reduction from baseline\n",
    "- Polynomial was selected as the final model and had a test RMSE of 358,000 dollars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439d7473",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48355eb",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a838d53b",
   "metadata": {},
   "source": [
    "- bathroom count and square footage had the strongest correlation with the target\n",
    "- county code, bedroom count, year built had a very weak correlation with the target\n",
    "- county code had the weakest relation to the home's value\n",
    "- square footage had the strongest correlation to home's value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c9ba7",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829f4f1b",
   "metadata": {},
   "source": [
    "#### The final model succeeded in outperforming the baseline RMSE by 18%. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446efbd1",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59048286",
   "metadata": {},
   "source": [
    "#### Utilize the Polynomial model made in order to reduce error in predicting the home's value by about 76,000 dollars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcef012a",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311ca833",
   "metadata": {},
   "source": [
    "- Further explore columns in the data set to further reduce error\n",
    "- Look for more features that may have a stronger correlation than current features given to the model\n",
    "- To find a prediction with less error it may be a good idea to find the property tax in 2017 for the cities where the home is located and create a feature that approximates the homes property tax using the target feature data and the tax rate for that area."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
